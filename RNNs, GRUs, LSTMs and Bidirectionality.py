# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VdLE-bEpum_vGdhw7rnyTo8r2fWx0UOd
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist

(x_train,y_train),(x_test,y_test)=mnist.load_data()
x_train = x_train.astype("float32")/255.0
x_test = x_test.astype("float32")/255.0

model=keras.Sequential()
model.add(keras.Input(shape=(None,28)))
model.add(
    layers.SimpleRNN(512,return_sequences=True,activation='relu')#in this way we could stack multiple RNN
)
model.add(layers.SimpleRNN(512,activation='relu'))
model.add(layers.Dense(10))
print(model.summary())

model.compile(
    loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #learning rate
    metrics=["accuracy"]
)

model.fit(x_train,y_train,batch_size=64, epochs=5, verbose=2)
model.evaluate(x_train,y_train,batch_size=64, verbose=2)

#GRU
model=keras.Sequential()
model.add(keras.Input(shape=(None,28)))
model.add(
    layers.GRU(512,return_sequences=True,activation='tanh')
)
model.add(layers.GRU(512,activation='tanh'))
model.add(layers.Dense(10))
print(model.summary())

#LSTM
model=keras.Sequential()
model.add(keras.Input(shape=(None,28)))
model.add(
    layers.LSTM(512,return_sequences=True,activation='tanh')
)
model.add(layers.LSTM(512,activation='tanh'))
model.add(layers.Dense(10))
print(model.summary())

#bidirectional LSTM
model=keras.Sequential()
model.add(keras.Input(shape=(None,28)))
model.add(
    layers.Bidirectional(layers.LSTM(512,return_sequences=True,activation='tanh'))
)
model.add(layers.Bidirectional(layers.LSTM(512,activation='tanh')))
model.add(layers.Dense(10))
print(model.summary())

